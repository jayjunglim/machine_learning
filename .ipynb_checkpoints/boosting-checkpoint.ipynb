{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lsjsj92.tistory.com/522?category=853217\n",
    "\n",
    "## 부스팅(boosting)\n",
    "예측한 분류기가 예측을 틀린 부분에 있어서 가중치를 부여\n",
    "ex) AdaBoost, gradient boosting\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "맞추지 못하는 부분에 있어서 가중치를 부여함, 마지막에 모든 것을 결합한 예측 모델을 만들어냄\n",
    "\n",
    "\n",
    "![image of ](https://miro.medium.com/max/1700/0*paPv7vXuq4eBHZY7.png)\n",
    "\n",
    "- Gradient Boosting\n",
    "\n",
    "비슷하나 가중치 업데이트를 gradient desent 경사 하강법으로 진행한다. (실제값 - 예측값)을 최소화 하는 방향성으로 가중치를 업데이트\n",
    "sklearn의 GB는 알고리즘 자체의 학습시간도 오래걸리고 병렬처리도 안되어 더욱 더 느리다. 하이퍼 파라미터 튜닝도 오래걸리는 편\n",
    "RF와 하이퍼 파라미터는 똑같음\n",
    "\n",
    "- 추가 hyper parameter\n",
    " 1. loss: GB에서 사용할 비용함수, 특별한 이유가 없으면 default 인 deviance를 적용\n",
    " 2. learning_rate: 학습률, 적으면 학습이 더디고, 많으면 너무 뛰수 있다. 보통 0.05 ~ 0.2 사이의 값을 사용\n",
    " 3. n_estimators: weak learner의 갯수. 기본 값은 100이고 많으면 모델 성능이 좋아질 수 있지만 시간 소모가 크다.\n",
    " 4. subsample: weak learner가 학습에 사용하는 데이터의 샘플링의 비율 기본 값은 1이며 전체 학습 데이터를 기반으로 사용. 0.5면 50%만 사용\n",
    "\n",
    "\n",
    "- XGBoost(eXtra Gradient Boost)\n",
    "\n",
    "GBM을 기반으로 하고 있지만 좀더 빠르며 overfitting의 regularization 문제를 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics  import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linewalks-20\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:702: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "def get_human_dataset():\n",
    "    feature_name_df = pd.read_csv(\"./features.txt\", sep ='\\s+', header = None, names =['column_index','column_name'])\n",
    "    feature_name = feature_name_df.iloc[:,1].values.tolist()\n",
    "    \n",
    "    X_train = pd.read_csv('./X_train.txt', sep ='\\s+', names =feature_name)\n",
    "    X_test = pd.read_csv('./X_test.txt', sep = '\\s+', names = feature_name)\n",
    "    y_train = pd.read_csv('./y_train.txt', sep = '\\s+', header = None, names =['action'])\n",
    "    y_test = pd.read_csv('./y_test.txt', sep = '\\s+', header = None, names = ['action'])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9376\n",
      "시간  2094.0707857608795\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 0)\n",
    "gb_clf.fit(X_train, y_train.values.ravel()) #ravel(): y_train을 1d array로 펴주는 함수\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, gb_pred)\n",
    "print(\"정확도 : {0:.4f}\".format(acc))\n",
    "print(\"시간 \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search를 활용하여 튜닝. 시간이 오래걸리기 때문에 n_estimator와 learning_rate만 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 파라미터 : {'learning_rate': 0.05, 'n_estimators': 300}\n",
      "최고 예측 정확도 : 0.9008433079434167\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[100,300],\n",
    "    'learning_rate' : [0.05,0.1]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(gb_clf, param_grid = params, cv = 2, verbose = 1)\n",
    "grid_cv.fit(X_train, y_train.values.ravel())\n",
    "print('최고 파라미터 :', grid_cv.best_params_)\n",
    "print('최고 예측 정확도 :', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
